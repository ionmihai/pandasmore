[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "pandasmore",
    "section": "",
    "text": "The full documentation site is here, and the GitHub page is here.\nHere is a short description of some of the main functions (more details below and in the documentation):",
    "crumbs": [
      "pandasmore"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "pandasmore",
    "section": "Install",
    "text": "Install\npip install pandasmore",
    "crumbs": [
      "pandasmore"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "pandasmore",
    "section": "How to use",
    "text": "How to use\nFirst, we set up an example dataset to showcase the functions in this module.\n\nimport pandas as pd\nimport numpy as np\nimport pandasmore as pdm\n\n\nraw = pd.DataFrame(np.random.rand(15,2), \n                    columns=list('AB'), \n                    index=pd.MultiIndex.from_product(\n                        [[1,2, np.nan],[np.nan,'2010-01','2010-02','2010-02','2010-04']],\n                        names = ['firm_id','date'])\n                      ).reset_index()\nraw\n\n\n\n\n\n\n\n\nfirm_id\ndate\nA\nB\n\n\n\n\n0\n1.0\nNaN\n0.249370\n0.926335\n\n\n1\n1.0\n2010-01\n0.282501\n0.513859\n\n\n2\n1.0\n2010-02\n0.804278\n0.307171\n\n\n3\n1.0\n2010-02\n0.828895\n0.746789\n\n\n4\n1.0\n2010-04\n0.569099\n0.331814\n\n\n5\n2.0\nNaN\n0.533977\n0.823457\n\n\n6\n2.0\n2010-01\n0.207558\n0.401378\n\n\n7\n2.0\n2010-02\n0.086001\n0.959371\n\n\n8\n2.0\n2010-02\n0.054230\n0.993980\n\n\n9\n2.0\n2010-04\n0.062525\n0.200272\n\n\n10\nNaN\nNaN\n0.091012\n0.635409\n\n\n11\nNaN\n2010-01\n0.866369\n0.972394\n\n\n12\nNaN\n2010-02\n0.432087\n0.837597\n\n\n13\nNaN\n2010-02\n0.878219\n0.148009\n\n\n14\nNaN\n2010-04\n0.820386\n0.834821\n\n\n\n\n\n\n\n\ndf = pdm.setup_tseries(raw.query('firm_id==1'),\n                        time_var='date', time_var_format=\"%Y-%m\",\n                        freq='M')\ndf\n\n\n\n\n\n\n\n\ndate\ndtdate\nfirm_id\nA\nB\n\n\nMdate\n\n\n\n\n\n\n\n\n\n2010-01\n2010-01\n2010-01-01\n1.0\n0.282501\n0.513859\n\n\n2010-02\n2010-02\n2010-02-01\n1.0\n0.828895\n0.746789\n\n\n2010-04\n2010-04\n2010-04-01\n1.0\n0.569099\n0.331814\n\n\n\n\n\n\n\n\ndf = pdm.setup_panel(raw,\n                        panel_ids='firm_id',\n                        time_var='date', time_var_format=\"%Y-%m\",\n                        freq='M')\ndf\n\n\n\n\n\n\n\n\n\ndate\ndtdate\nA\nB\n\n\nfirm_id\nMdate\n\n\n\n\n\n\n\n\n1\n2010-01\n2010-01\n2010-01-01\n0.282501\n0.513859\n\n\n2010-02\n2010-02\n2010-02-01\n0.828895\n0.746789\n\n\n2010-04\n2010-04\n2010-04-01\n0.569099\n0.331814\n\n\n2\n2010-01\n2010-01\n2010-01-01\n0.207558\n0.401378\n\n\n2010-02\n2010-02\n2010-02-01\n0.054230\n0.993980\n\n\n2010-04\n2010-04\n2010-04-01\n0.062525\n0.200272\n\n\n\n\n\n\n\n\npdm.lag(df['A'])\n\nfirm_id  Mdate  \n1        2010-01         NaN\n         2010-02    0.282501\n         2010-04         NaN\n2        2010-01         NaN\n         2010-02    0.207558\n         2010-04         NaN\nName: A_lag1, dtype: float64",
    "crumbs": [
      "pandasmore"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "Almost all these functions make a copy of the input DataFrame. When that DataFrame is large, use these functions as df = func(df).\nExported source\nfrom __future__ import annotations\nfrom typing import List, Callable \nimport os, glob \nimport pandas as pd\nimport numpy as np\nFirst, we set up an example dataset to showcase the functions in this module.\nraw = pd.DataFrame(np.random.rand(15,2), \n                  columns=list('AB'), \n                  index=pd.MultiIndex.from_product(\n                      [[1,2, np.nan],[np.nan,'2010-01','2010-02','2010-02','2010-04']],\n                      names = ['permno','date'])\n                    ).reset_index()\nraw\n\n\n\n\n\n\n\n\npermno\ndate\nA\nB\n\n\n\n\n0\n1.0\nNaN\n0.234344\n0.698915\n\n\n1\n1.0\n2010-01\n0.104762\n0.923778\n\n\n2\n1.0\n2010-02\n0.134963\n0.287128\n\n\n3\n1.0\n2010-02\n0.561185\n0.629761\n\n\n4\n1.0\n2010-04\n0.452953\n0.137185\n\n\n5\n2.0\nNaN\n0.242651\n0.010276\n\n\n6\n2.0\n2010-01\n0.481129\n0.734026\n\n\n7\n2.0\n2010-02\n0.663068\n0.887246\n\n\n8\n2.0\n2010-02\n0.627125\n0.525601\n\n\n9\n2.0\n2010-04\n0.413195\n0.860653\n\n\n10\nNaN\nNaN\n0.858186\n0.907775\n\n\n11\nNaN\n2010-01\n0.660384\n0.601805\n\n\n12\nNaN\n2010-02\n0.037070\n0.510598\n\n\n13\nNaN\n2010-02\n0.579008\n0.682778\n\n\n14\nNaN\n2010-04\n0.697347\n0.750504",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#common-panel-setup-procedures",
    "href": "core.html#common-panel-setup-procedures",
    "title": "core",
    "section": "Common panel setup procedures",
    "text": "Common panel setup procedures\n\nsource\n\norder_columns\n\n order_columns (df:pandas.core.frame.DataFrame, these_first:List[str])\n\nReturns df with reordered columns. Use as df = order_columns(df,_)\n\norder_columns(raw, these_first=['B']).head()\n\n\n\n\n\n\n\n\nB\npermno\ndate\nA\n\n\n\n\n0\n0.698915\n1.0\nNaN\n0.234344\n\n\n1\n0.923778\n1.0\n2010-01\n0.104762\n\n\n2\n0.287128\n1.0\n2010-02\n0.134963\n\n\n3\n0.629761\n1.0\n2010-02\n0.561185\n\n\n4\n0.137185\n1.0\n2010-04\n0.452953\n\n\n\n\n\n\n\n\nsource\n\n\nprocess_dates\n\n process_dates (df:pandas.core.frame.DataFrame, time_var:str='date',\n                time_var_format:str='%Y-%m-%d', dtdate_var:str='dtdate',\n                freq:str=None)\n\nMakes datetime date dtdate_var from time_var; adds period date f'{freq}date'.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nFunction returns copy of this df with dtdate_var and f'{freq}date' cols added\n\n\ntime_var\nstr\ndate\nThis will be the date variable used to generate datetime var dtdate_var\n\n\ntime_var_format\nstr\n%Y-%m-%d\nFormat of time_var; must be valid pandas strftime\n\n\ndtdate_var\nstr\ndtdate\nName of datetime var to be created from time_var\n\n\nfreq\nstr\nNone\nUsed to create f'{freq}date' period date; must be valid pandas offset string\n\n\nReturns\nDataFrame\n\n\n\n\n\n\nnewdf = process_dates(raw, time_var_format=\"%Y-%m\", freq='M')\nnewdf.head()\n\n\n\n\n\n\n\n\ndate\ndtdate\nMdate\npermno\nA\nB\n\n\n\n\n0\nNaN\nNaT\nNaT\n1.0\n0.234344\n0.698915\n\n\n1\n2010-01\n2010-01-01\n2010-01\n1.0\n0.104762\n0.923778\n\n\n2\n2010-02\n2010-02-01\n2010-02\n1.0\n0.134963\n0.287128\n\n\n3\n2010-02\n2010-02-01\n2010-02\n1.0\n0.561185\n0.629761\n\n\n4\n2010-04\n2010-04-01\n2010-04\n1.0\n0.452953\n0.137185\n\n\n\n\n\n\n\n\nsource\n\n\nsetup_tseries\n\n setup_tseries (df:pandas.core.series.Series|pandas.core.frame.DataFrame,\n                dates_processed:bool=False, time_var:str='date',\n                time_var_format:str='%Y-%m-%d', dtdate_var:str='dtdate',\n                freq:str=None, drop_missing_index_vals:bool=True,\n                drop_index_duplicates:bool=True,\n                duplicates_which_keep:str='last')\n\nApplies process_dates to df; cleans up resulting f'{freq}date' period date and sets it as index.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\npandas.core.series.Series | pandas.core.frame.DataFrame\n\nInput DataFrame; a copy is returned\n\n\ndates_processed\nbool\nFalse\nIf True, assumes dates are already processed with process_dates\n\n\ntime_var\nstr\ndate\nThis will be the date variable used to generate datetime var dtdate_var\n\n\ntime_var_format\nstr\n%Y-%m-%d\nFormat of time_var; must be valid pandas strftime\n\n\ndtdate_var\nstr\ndtdate\nName of datetime var to be created from time_var\n\n\nfreq\nstr\nNone\nUsed to create f'{freq}date' period date; must be valid pandas offset string\n\n\ndrop_missing_index_vals\nbool\nTrue\nWhat to do with missing f'{freq}date'\n\n\ndrop_index_duplicates\nbool\nTrue\nWhat to do with duplicates in f'{freq}date' values\n\n\nduplicates_which_keep\nstr\nlast\nIf duplicates in index, which to keep; must be ‘first’, ‘last’ or False\n\n\nReturns\nDataFrame\n\n\n\n\n\n\nraw.query('permno==1')\n\n\n\n\n\n\n\n\npermno\ndate\nA\nB\n\n\n\n\n0\n1.0\nNaN\n0.234344\n0.698915\n\n\n1\n1.0\n2010-01\n0.104762\n0.923778\n\n\n2\n1.0\n2010-02\n0.134963\n0.287128\n\n\n3\n1.0\n2010-02\n0.561185\n0.629761\n\n\n4\n1.0\n2010-04\n0.452953\n0.137185\n\n\n\n\n\n\n\n\ndf = setup_tseries(raw.query('permno==1'),\n                 time_var='date', time_var_format=\"%Y-%m\",\n                 freq='M')\ndf\n\n\n\n\n\n\n\n\ndate\ndtdate\npermno\nA\nB\n\n\nMdate\n\n\n\n\n\n\n\n\n\n2010-01\n2010-01\n2010-01-01\n1.0\n0.104762\n0.923778\n\n\n2010-02\n2010-02\n2010-02-01\n1.0\n0.561185\n0.629761\n\n\n2010-04\n2010-04\n2010-04-01\n1.0\n0.452953\n0.137185\n\n\n\n\n\n\n\n\nsource\n\n\nsetup_panel\n\n setup_panel (df:pandas.core.frame.DataFrame, panel_ids:str=None,\n              dates_processed:bool=False, time_var:str='date',\n              time_var_format:str='%Y-%m-%d', dtdate_var:str='dtdate',\n              freq:str=None, drop_missing_index_vals:bool=True,\n              panel_ids_toint:str='Int64',\n              drop_index_duplicates:bool=True,\n              duplicates_which_keep:str='last')\n\nApplies process_dates to df; cleans up (panel_ids ,f'{freq}date') and sets it as index.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nInput DataFrame; a copy is returned\n\n\npanel_ids\nstr\nNone\nName of variable that identifies panel entities\n\n\ndates_processed\nbool\nFalse\nIf True, assumes dates are already processed with process_dates\n\n\ntime_var\nstr\ndate\nThis will be the date variable used to generate datetime var dtdate_var\n\n\ntime_var_format\nstr\n%Y-%m-%d\nFormat of time_var; must be valid pandas strftime\n\n\ndtdate_var\nstr\ndtdate\nName of datetime var to be created from time_var\n\n\nfreq\nstr\nNone\nUsed to create f'{freq}date' period date; must be valid pandas offset string\n\n\ndrop_missing_index_vals\nbool\nTrue\nWhat to do with missing panel_ids or f'{freq}date'\n\n\npanel_ids_toint\nstr\nInt64\nConverts panel_ids to int in place; use falsy value if not wanted\n\n\ndrop_index_duplicates\nbool\nTrue\nWhat to do with duplicates in (panel_ids, f'{freq}date') values\n\n\nduplicates_which_keep\nstr\nlast\nIf duplicates in index, which to keep; must be ‘first’, ‘last’ or False\n\n\nReturns\nDataFrame\n\n\n\n\n\n\ndf = setup_panel(raw,\n                 panel_ids='permno',\n                 time_var='date', time_var_format=\"%Y-%m\",\n                 freq='M')\ndf\n\n\n\n\n\n\n\n\n\ndate\ndtdate\nA\nB\n\n\npermno\nMdate\n\n\n\n\n\n\n\n\n1\n2010-01\n2010-01\n2010-01-01\n0.104762\n0.923778\n\n\n2010-02\n2010-02\n2010-02-01\n0.561185\n0.629761\n\n\n2010-04\n2010-04\n2010-04-01\n0.452953\n0.137185\n\n\n2\n2010-01\n2010-01\n2010-01-01\n0.481129\n0.734026\n\n\n2010-02\n2010-02\n2010-02-01\n0.627125\n0.525601\n\n\n2010-04\n2010-04\n2010-04-01\n0.413195\n0.860653",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#robust-lagging",
    "href": "core.html#robust-lagging",
    "title": "core",
    "section": "Robust lagging",
    "text": "Robust lagging\nLagging with shift fails when we have (1) panel data, (2) gaps in the time-series, (3) duplicate dates, (4) data is not sorted by dates (5) NaN dates.\nThe fast_lag function below correctly lags data (using shift()), assuming we do not have problems (2), (3), (4), and (5).\nThe lag function below correctly lags data (using merge()), assuming we do not have problem (5).\n\nsource\n\nfast_lag\n\n fast_lag (df:pandas.core.series.Series|pandas.core.frame.DataFrame,\n           n:int=1)\n\nLag data in df by n periods. ASSUMES DATA IS SORTED BY DATES AND HAS NO DUPLICATE OR NaN DATES, AND NO GAPS IN THE TIME SERIES. Apply df = setup_panel(df) before using.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\npandas.core.series.Series | pandas.core.frame.DataFrame\n\nIndex of df (or level 1 of MultiIndex) must be pandas period date.\n\n\nn\nint\n1\nNumber of periods to lag based on frequency of df.index; Negative values means lead.\n\n\nReturns\nSeries\n\n**Series with lagged values of df; Name is taken from df.columns[0], with ’_lag{n}’ or ’_lead{n}’ suffixed.**\n\n\n\n\nsource\n\n\nlag\n\n lag (df:pandas.core.series.Series|pandas.core.frame.DataFrame, n:int=1,\n      fast:bool=False)\n\nLag data in ‘df’ by ‘n’ periods. ASSUMES NO NaN DATES. Apply df = setup_panel(df) before using.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\npandas.core.series.Series | pandas.core.frame.DataFrame\n\nIndex (or level 1 of MultiIndex) must be period date with no missing values.\n\n\nn\nint\n1\nNumber of periods to lag based on frequency of df.index; Negative values means lead.\n\n\nfast\nbool\nFalse\nIf True, uses fast_lag(), which assumes data is sorted by date and has no duplicate or missing dates\n\n\nReturns\nSeries\n\n**Series with lagged values of df; Name is taken from df.columns[0], with ’_lag{n}’ or ’_lead{n}’ suffixed.**\n\n\n\nThe index of the df parameter can not contain missing values.\n\nlag(df['A'])\n\npermno  Mdate  \n1       2010-01         NaN\n        2010-02    0.104762\n        2010-04         NaN\n2       2010-01         NaN\n        2010-02    0.481129\n        2010-04         NaN\nName: A_lag1, dtype: float64\n\n\n\nlag(df['A'],fast=False)\n\npermno  Mdate  \n1       2010-01         NaN\n        2010-02    0.104762\n        2010-04         NaN\n2       2010-01         NaN\n        2010-02    0.481129\n        2010-04         NaN\nName: A_lag1, dtype: float64\n\n\n\nsource\n\n\nadd_lags\n\n add_lags (df:pandas.core.series.Series|pandas.core.frame.DataFrame,\n           vars:Union[str,List[str]], lags:Union[int,List[int]]=1,\n           lag_suffix:str='_lag', lead_suffix:str='_lead',\n           use_fast_lags:bool=False)\n\nReturns a copy of df with all lags of all vars added to it.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\npandas.core.series.Series | pandas.core.frame.DataFrame\n\nIf pd.Series, it must have a name equal to vars param\n\n\nvars\nUnion\n\nVariables to be lagged; must be a subset of df.columns()\n\n\nlags\nUnion\n1\nWhich lags to be added\n\n\nlag_suffix\nstr\n_lag\nUsed to create new lagged variable names\n\n\nlead_suffix\nstr\n_lead\nUsed to create new lead variable names\n\n\nuse_fast_lags\nbool\nFalse\nWeather to use fast_lag() function when lagging\n\n\nReturns\nDataFrame\n\n\n\n\n\nBecause this makes a copy of df, when df is a large dataset, this should be used as df = add_lags(df).\n\nadd_lags(df['A'], vars='A')\n\n\n\n\n\n\n\n\n\nA\nA_lag1\n\n\npermno\nMdate\n\n\n\n\n\n\n1\n2010-01\n0.104762\nNaN\n\n\n2010-02\n0.561185\n0.104762\n\n\n2010-04\n0.452953\nNaN\n\n\n2\n2010-01\n0.481129\nNaN\n\n\n2010-02\n0.627125\n0.481129\n\n\n2010-04\n0.413195\nNaN\n\n\n\n\n\n\n\n\nadd_lags(df, vars=['A','B'], lags=[2,-1])\n\n\n\n\n\n\n\n\n\ndate\ndtdate\nA\nB\nA_lag2\nA_lead1\nB_lag2\nB_lead1\n\n\npermno\nMdate\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2010-01\n2010-01\n2010-01-01\n0.104762\n0.923778\nNaN\n0.561185\nNaN\n0.629761\n\n\n2010-02\n2010-02\n2010-02-01\n0.561185\n0.629761\nNaN\nNaN\nNaN\nNaN\n\n\n2010-04\n2010-04\n2010-04-01\n0.452953\n0.137185\n0.561185\nNaN\n0.629761\nNaN\n\n\n2\n2010-01\n2010-01\n2010-01-01\n0.481129\n0.734026\nNaN\n0.627125\nNaN\n0.525601\n\n\n2010-02\n2010-02\n2010-02-01\n0.627125\n0.525601\nNaN\nNaN\nNaN\nNaN\n\n\n2010-04\n2010-04\n2010-04-01\n0.413195\n0.860653\n0.627125\nNaN\n0.525601\nNaN\n\n\n\n\n\n\n\n\nadd_lags(df,vars=['A','B'],lags=[2,-2], lag_suffix='_lg', lead_suffix='_ld')\n\n\n\n\n\n\n\n\n\ndate\ndtdate\nA\nB\nA_lg2\nA_ld2\nB_lg2\nB_ld2\n\n\npermno\nMdate\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2010-01\n2010-01\n2010-01-01\n0.104762\n0.923778\nNaN\nNaN\nNaN\nNaN\n\n\n2010-02\n2010-02\n2010-02-01\n0.561185\n0.629761\nNaN\n0.452953\nNaN\n0.137185\n\n\n2010-04\n2010-04\n2010-04-01\n0.452953\n0.137185\n0.561185\nNaN\n0.629761\nNaN\n\n\n2\n2010-01\n2010-01\n2010-01-01\n0.481129\n0.734026\nNaN\nNaN\nNaN\nNaN\n\n\n2010-02\n2010-02\n2010-02-01\n0.627125\n0.525601\nNaN\n0.413195\nNaN\n0.860653\n\n\n2010-04\n2010-04\n2010-04-01\n0.413195\n0.860653\n0.627125\nNaN\n0.525601\nNaN\n\n\n\n\n\n\n\nAnd remember that by default, lag uses fast=True, which is not robust to duplicate dates (or unsorted dates).",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#utilities-using-robust-lagging",
    "href": "core.html#utilities-using-robust-lagging",
    "title": "core",
    "section": "Utilities using robust lagging",
    "text": "Utilities using robust lagging\n\nsource\n\nrpct_change\n\n rpct_change (df:pandas.core.series.Series, n:int=1, use_fast_lags=False)\n\nPercentage change using robust lag() or fast_lag() function.\n\nrpct_change(df['A'])\n\npermno  Mdate  \n1       2010-01         NaN\n        2010-02    4.356736\n        2010-04         NaN\n2       2010-01         NaN\n        2010-02    0.303446\n        2010-04         NaN\ndtype: float64\n\n\n\nsource\n\n\nrdiff\n\n rdiff (df:pandas.core.series.Series, n:int=1, use_fast_lags=False)\n\nDifference using robust lag() or fast_lag() function.\n\nrdiff(df['A'])\n\npermno  Mdate  \n1       2010-01         NaN\n        2010-02    0.456422\n        2010-04         NaN\n2       2010-01         NaN\n        2010-02    0.145997\n        2010-04         NaN\ndtype: float64\n\n\n\nsource\n\n\nrrolling\n\n rrolling (df:pandas.core.series.Series|pandas.core.frame.DataFrame,\n           func:str, window:int=None, skipna:bool|None=False,\n           use_fast_lags:bool=False)\n\nLike pd.DataFrame.rolling but using robust lags. Run df = setup_tseries(df) or df = setup_panel(df) prior to using.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\npandas.core.series.Series | pandas.core.frame.DataFrame\n\nMust have period date Index (if Series) or (panel_id, period_date) Multiindex (if DataFrame)\n\n\nfunc\nstr\n\nName of any pandas aggregation function (to applied to df data within each rolling window\n\n\nwindow\nint\nNone\nRolling window length; if None, uses ‘expanding’ without fixing lags\n\n\nskipna\nbool | None\nFalse\nUse None if func does not take skipna arg.\n\n\nuse_fast_lags\nbool\nFalse\n\n\n\nReturns\nSeries\n\n\n\n\n\n\ndf.assign(rolling_A = rrolling(df['A'], func='mean', window=2, skipna=True))\n\n\n\n\n\n\n\n\n\ndate\ndtdate\nA\nB\nrolling_A\n\n\npermno\nMdate\n\n\n\n\n\n\n\n\n\n1\n2010-01\n2010-01\n2010-01-01\n0.104762\n0.923778\n0.104762\n\n\n2010-02\n2010-02\n2010-02-01\n0.561185\n0.629761\n0.332974\n\n\n2010-04\n2010-04\n2010-04-01\n0.452953\n0.137185\n0.452953\n\n\n2\n2010-01\n2010-01\n2010-01-01\n0.481129\n0.734026\n0.481129\n\n\n2010-02\n2010-02\n2010-02-01\n0.627125\n0.525601\n0.554127\n\n\n2010-04\n2010-04\n2010-04-01\n0.413195\n0.860653\n0.413195\n\n\n\n\n\n\n\n\ndf.assign(rolling_A = rrolling(df['A'], func='mean', window=2, skipna=False))\n\n\n\n\n\n\n\n\n\ndate\ndtdate\nA\nB\nrolling_A\n\n\npermno\nMdate\n\n\n\n\n\n\n\n\n\n1\n2010-01\n2010-01\n2010-01-01\n0.104762\n0.923778\nNaN\n\n\n2010-02\n2010-02\n2010-02-01\n0.561185\n0.629761\n0.332974\n\n\n2010-04\n2010-04\n2010-04-01\n0.452953\n0.137185\nNaN\n\n\n2\n2010-01\n2010-01\n2010-01-01\n0.481129\n0.734026\nNaN\n\n\n2010-02\n2010-02\n2010-02-01\n0.627125\n0.525601\n0.554127\n\n\n2010-04\n2010-04\n2010-04-01\n0.413195\n0.860653\nNaN\n\n\n\n\n\n\n\nTest that it works for a time-series, not just a panel\n\ndf['A'].loc[1]\n\nMdate\n2010-01    0.104762\n2010-02    0.561185\n2010-04    0.452953\nFreq: M, Name: A, dtype: float64\n\n\n\nrrolling(df['A'].loc[1], func='mean', window=2, skipna=True)\n\nMdate\n2010-01    0.104762\n2010-02    0.332974\n2010-04    0.452953\nFreq: M, dtype: float64",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#very-common-data-transformations",
    "href": "core.html#very-common-data-transformations",
    "title": "core",
    "section": "Very common data transformations",
    "text": "Very common data transformations\n\nsource\n\nwins\n\n wins (df:pandas.core.series.Series|pandas.core.frame.DataFrame, low=0.01,\n       high=0.99, byvars:List[str]=None)\n\nWinsorizes all columns in df.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\npandas.core.series.Series | pandas.core.frame.DataFrame\n\n\n\n\nlow\nfloat\n0.01\nLower quantile at which to winsorize\n\n\nhigh\nfloat\n0.99\nUpper quantile at which to winsorize\n\n\nbyvars\nList\nNone\nIf None, quantiles use full sample, o/w they are calculate within each group given by byvars\n\n\nReturns\nDataFrame\n\n\n\n\n\n\nsource\n\n\nnorm\n\n norm (df:pandas.core.series.Series|pandas.core.frame.DataFrame,\n       divide_by_mean=False)\n\nSubtract means from all columns of df and divide by their std. deviations, unless divide_by_mean is True",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#io",
    "href": "core.html#io",
    "title": "core",
    "section": "I/O",
    "text": "I/O\n\nsource\n\nto_stata\n\n to_stata (df:pandas.core.frame.DataFrame=None, outfile:str=None,\n           obj_drop:bool=False, obj_to_str:bool=False, **to_stata_kwargs)\n\nWrites df to stata outfile\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\nNone\n\n\n\noutfile\nstr\nNone\nOutput file path; must include .dta extension\n\n\nobj_drop\nbool\nFalse\nWhether to drop all columns of object type\n\n\nobj_to_str\nbool\nFalse\nWhether to convert all columns of object type to string type\n\n\nto_stata_kwargs\nVAR_KEYWORD\n\n\n\n\n\nIndex data is automatically included in the output, unless the index is the default range from 0 to len(df).\nColumns of object data type are by default left to pd.to_stata to figure out how to convert. Note that columns of strings with missing data might cause an error in this default case. In this case, the best thing to do is for you convert it to string type before calling this function. If not, setting obj_to_str to True will deal with this internally but it will be slower.\nFor time data, columns of period type and columns of datetime64[ns] type with time zone information will be dropped. All other datetime64[ns] variables will be converted to td dates in Stata.\n\nto_stata(df, outfile='../data/df.dta', version=117)\n\n\ndf = pd.read_stata('../data/df.dta')\ndf\n\n\n\n\n\n\n\n\npermno\ndate\ndtdate\nA\nB\n\n\n\n\n0\n1\n2010-01\n2010-01-01\n0.104762\n0.923778\n\n\n1\n1\n2010-02\n2010-02-01\n0.561185\n0.629761\n\n\n2\n1\n2010-04\n2010-04-01\n0.452953\n0.137185\n\n\n3\n2\n2010-01\n2010-01-01\n0.481129\n0.734026\n\n\n4\n2\n2010-02\n2010-02-01\n0.627125\n0.525601\n\n\n5\n2\n2010-04\n2010-04-01\n0.413195\n0.860653",
    "crumbs": [
      "core"
    ]
  }
]